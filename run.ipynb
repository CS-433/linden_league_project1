{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e89eb2-4476-414d-8078-a6773ed6ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utils import (\n",
    "    split_data,\n",
    "    get_cross_val_scores,\n",
    "    prep_hyperparam_search,\n",
    "    now_str,\n",
    "    accuracy,\n",
    "    f1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5340e",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4ae70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = load_clean_data()\n",
    "x, x_final, y, ids, ids_final = all_data[\"x\"], all_data[\"x_final\"], all_data[\"y\"], all_data[\"ids\"], all_data[\"ids_final\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80833d7e",
   "metadata": {},
   "source": [
    "## Run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utils import (\n",
    "    split_data,\n",
    "    get_cross_val_scores,\n",
    "    prep_hyperparam_search,\n",
    "    now_str,\n",
    "    accuracy,\n",
    "    f1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed425016",
   "metadata": {},
   "source": [
    "#### Set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b438792",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"seed\": 0,\n",
    "    \"verbose\": False,\n",
    "    \"scoring_fn\": f1,\n",
    "    \"train\": {\n",
    "        \"cv\": None,\n",
    "        # \"cv\": {\n",
    "        #     \"k_folds\": 5,\n",
    "        #     \"shuffle\": False,\n",
    "        # },\n",
    "        \"holdout\": {\n",
    "            \"split_frac\": 0.2,\n",
    "            \"seed\": 0,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "if cfg[\"train\"].get(\"cv\", None) is not None:\n",
    "    cfg[\"train\"][\"cv\"][\"scoring_fn\"] = cfg[\"scoring_fn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d6417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model_cls\": LogisticRegression,\n",
    "        \"hyperparam_search\": {\n",
    "            \"C\": [0.5, 5],\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"max_iter\": [500],\n",
    "            \"class_weight\": [None, \"balanced\"],\n",
    "            \"verbose\": [1 if cfg[\"verbose\"] else 0],\n",
    "            \"random_state\": [cfg[\"seed\"]],\n",
    "        },\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"model_cls\": DecisionTreeClassifier,\n",
    "        \"hyperparam_search\": {\n",
    "            \"max_depth\": [5, 10, 30],\n",
    "            \"class_weight\": [None, \"balanced\"],\n",
    "            \"random_state\": [cfg[\"seed\"]],\n",
    "        },\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model_cls\": RandomForestClassifier,\n",
    "        \"hyperparam_search\": {\n",
    "            # \"n_estimators\": [20, 80],\n",
    "            \"n_estimators\": [80],\n",
    "            # \"max_depth\": [3, 10],\n",
    "            \"max_depth\": [3],\n",
    "            \"class_weight\": [None, \"balanced\"],\n",
    "            \"n_jobs\": [-1],\n",
    "            \"verbose\": [1 if cfg[\"verbose\"] else 0],\n",
    "            \"random_state\": [cfg[\"seed\"]],\n",
    "        },\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model_cls\": GradientBoostingClassifier,\n",
    "        \"hyperparam_search\": {\n",
    "            # \"n_estimators\": [40, 100],\n",
    "            \"n_estimators\": [40],\n",
    "            \"max_depth\": [3],\n",
    "            \"verbose\": [1 if cfg[\"verbose\"] else 0],\n",
    "            \"random_state\": [cfg[\"seed\"]],\n",
    "        },\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model_cls\": XGBClassifier,\n",
    "        \"hyperparam_search\": {\n",
    "            # \"n_estimators\": [20, 60, 120],\n",
    "            \"n_estimators\": [60],\n",
    "            # \"max_depth\": [3, 10],\n",
    "            \"max_depth\": [3],\n",
    "            \"n_jobs\": [-1],\n",
    "            \"verbosity\": [1 if cfg[\"verbose\"] else 0],\n",
    "            \"random_state\": [cfg[\"seed\"]],\n",
    "        },\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"model_cls\": MLPClassifier,\n",
    "        \"hyperparam_search\": {\n",
    "            # \"hidden_layer_sizes\": [(64,), (32, 32), (16, 32, 16)],\n",
    "            \"hidden_layer_sizes\": [(64,)],\n",
    "            # \"alpha\": [5e-5, 1e-3],\n",
    "            \"alpha\": [5e-5],\n",
    "            \"early_stopping\": [True],\n",
    "            \"max_iter\": [300],\n",
    "            \"verbose\": [1 if cfg[\"verbose\"] else 0],\n",
    "            \"random_state\": [cfg[\"seed\"]],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36818b9",
   "metadata": {},
   "source": [
    "#### Run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4fc05af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Logistic Regression\n",
      "  Searching hyperparameters among 4 options...\n",
      "  Holdout validation with 0.2 split...\n",
      "  Hyperparameters selected: C=5 penalty=l2 max_iter=500 class_weight=balanced verbose=0 random_state=0\n",
      "  Training on all data with best hyperparameters...\n",
      "  Results:\n",
      "    Training f1: 0.3428\n",
      "    Validation f1: 0.3420\n",
      "    Hyperparameters: C=5 penalty=l2 max_iter=500 class_weight=balanced verbose=0 random_state=0\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Decision Tree\n",
      "  Searching hyperparameters among 6 options...\n",
      "  Holdout validation with 0.2 split...\n",
      "  Hyperparameters selected: max_depth=10 class_weight=balanced random_state=0\n",
      "  Training on all data with best hyperparameters...\n",
      "  Results:\n",
      "    Training f1: 0.3591\n",
      "    Validation f1: 0.3351\n",
      "    Hyperparameters: max_depth=10 class_weight=balanced random_state=0\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Random Forest\n",
      "  Searching hyperparameters among 2 options...\n",
      "  Holdout validation with 0.2 split...\n",
      "  Hyperparameters selected: n_estimators=80 max_depth=3 class_weight=balanced n_jobs=-1 verbose=0 random_state=0\n",
      "  Training on all data with best hyperparameters...\n",
      "  Results:\n",
      "    Training f1: 0.2938\n",
      "    Validation f1: 0.2939\n",
      "    Hyperparameters: n_estimators=80 max_depth=3 class_weight=balanced n_jobs=-1 verbose=0 random_state=0\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Gradient Boosting\n",
      "  Searching hyperparameters among 1 options...\n",
      "  Holdout validation with 0.2 split...\n",
      "  Hyperparameters selected: n_estimators=40 max_depth=3 verbose=0 random_state=0\n",
      "  Training on all data with best hyperparameters...\n",
      "  Results:\n",
      "    Training f1: 0.1208\n",
      "    Validation f1: 0.1121\n",
      "    Hyperparameters: n_estimators=40 max_depth=3 verbose=0 random_state=0\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "XGBoost\n",
      "  Searching hyperparameters among 1 options...\n",
      "  Holdout validation with 0.2 split...\n",
      "  Hyperparameters selected: n_estimators=60 max_depth=3 n_jobs=-1 verbosity=0 random_state=0\n",
      "  Training on all data with best hyperparameters...\n",
      "  Results:\n",
      "    Training f1: 0.1860\n",
      "    Validation f1: 0.1814\n",
      "    Hyperparameters: n_estimators=60 max_depth=3 n_jobs=-1 verbosity=0 random_state=0\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "MLP\n",
      "  Searching hyperparameters among 1 options...\n",
      "  Holdout validation with 0.2 split...\n",
      "  Hyperparameters selected: hidden_layer_sizes=(64,) alpha=5e-05 early_stopping=True max_iter=300 verbose=0 random_state=0\n",
      "  Training on all data with best hyperparameters...\n",
      "  Results:\n",
      "    Training f1: 0.1585\n",
      "    Validation f1: 0.1321\n",
      "    Hyperparameters: hidden_layer_sizes=(64,) alpha=5e-05 early_stopping=True max_iter=300 verbose=0 random_state=0\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Best model: Logistic Regression\n",
      "Validation f1: 0.3420\n"
     ]
    }
   ],
   "source": [
    "dir_name = os.path.join(CLEAN_DATA_PATH, \"runs\", now_str())\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "best = {\"model_name\": None, \"val_score\": 0}\n",
    "for name, run_dict in runs.items():\n",
    "    print(\"---\" * 50)\n",
    "    print(f\"{name}\")\n",
    "\n",
    "    ### hyperparam search\n",
    "    hyperparam_search = prep_hyperparam_search(run_dict[\"hyperparam_search\"])\n",
    "    print(f\"  Searching hyperparameters among {len(hyperparam_search)} options...\")\n",
    "    seed_all(cfg[\"seed\"])\n",
    "    if cfg[\"train\"].get(\"cv\", None) is not None:\n",
    "        ### cross-validation\n",
    "        print(f\"  Cross-validating with {cfg['train']['cv']['k_folds']}-fold cross-validation...\")\n",
    "        cv_scores = []\n",
    "        for hp_comb in hyperparam_search:\n",
    "            seed_all(cfg[\"seed\"])\n",
    "            model = run_dict[\"model_cls\"](**hp_comb)\n",
    "            hp_scores = get_cross_val_scores(model, x, y, **cfg[\"train\"][\"cv\"])\n",
    "            cv_scores.append(np.mean(hp_scores))\n",
    "        best_hp_comb_idx = np.argmax(cv_scores)\n",
    "        run_dict[\"hyperparams\"] = hyperparam_search[best_hp_comb_idx]\n",
    "        run_dict[\"val_score\"] = cv_scores[best_hp_comb_idx]\n",
    "    elif cfg[\"train\"].get(\"holdout\", None) is not None:\n",
    "        ### validation holdout\n",
    "        print(f\"  Holdout validation with {cfg['train']['holdout']['split_frac']} split...\")\n",
    "        x_train, x_val, y_train, y_val = split_data(x, y, **cfg[\"train\"][\"holdout\"])\n",
    "        val_scores = []\n",
    "        for hp_comb in hyperparam_search:\n",
    "            model = run_dict[\"model_cls\"](**hp_comb)\n",
    "            model.fit(x_train, y_train)\n",
    "            y_val_pred = model.predict(x_val)\n",
    "            val_score = cfg[\"scoring_fn\"](y_val, y_val_pred)\n",
    "            val_scores.append(val_score)\n",
    "        best_hp_comb_idx = np.argmax(val_scores)\n",
    "        run_dict[\"hyperparams\"] = hyperparam_search[best_hp_comb_idx]\n",
    "        run_dict[\"val_score\"] = val_scores[best_hp_comb_idx]\n",
    "    else:\n",
    "        ### just train on all data\n",
    "        print(\"  No validation method specified. Training on all data with the first hyperparameter combination.\")\n",
    "        run_dict[\"hyperparams\"] = hyperparam_search[0]\n",
    "        run_dict[\"val_score\"] = None\n",
    "    print(f\"  Hyperparameters selected: {' '.join([f'{k}={v}' for k, v in run_dict['hyperparams'].items()])}\")\n",
    "\n",
    "    ### train on all data\n",
    "    print(f\"  Training on all data with best hyperparameters...\")\n",
    "    model = run_dict[\"model_cls\"](**run_dict[\"hyperparams\"])\n",
    "    model.fit(x, y)\n",
    "    run_dict[\"model\"] = model\n",
    "    run_dict[\"train_score\"] = cfg[\"scoring_fn\"](y, model.predict(x))\n",
    "    print(\n",
    "        \"  Results:\"\n",
    "        f\"\\n    Training {cfg['scoring_fn'].__name__}: {run_dict['train_score']:.4f}\"\n",
    "        f\"\\n    Validation {cfg['scoring_fn'].__name__}: {run_dict['val_score']:.4f}\"\n",
    "        f\"\\n    Hyperparameters: {' '.join([f'{k}={v}' for k, v in run_dict['hyperparams'].items()])}\"\n",
    "    )\n",
    "\n",
    "    ### save run\n",
    "    file_name = f\"{name.replace(' ', '_')}.pkl\"\n",
    "    with open(os.path.join(dir_name, file_name), \"wb\") as f:\n",
    "        pickle.dump(run_dict, f)\n",
    "\n",
    "    ### save best\n",
    "    if run_dict[\"val_score\"] > best[\"val_score\"]:\n",
    "        best[\"model_name\"] = name\n",
    "        best[\"val_score\"] = run_dict[\"val_score\"]\n",
    "\n",
    "print(\"---\" * 50)\n",
    "print(f\"Best model: {best['model_name']}\")\n",
    "print(f\"Validation {cfg['scoring_fn'].__name__}: {best['val_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
